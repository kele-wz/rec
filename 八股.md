机器学习基础

### model.train()和model.eval()

- **Q：有什么不同**

  **R：**对一些如Dropout，BatchNormalization这种在训练和预测阶段表现不一样的层进行修改。model.eval()时，Dropout层会关闭，并且BN会停止计算和更新mean和var(BN 在训练时会先计算mean和var，然后才能进行归一化操作)。

   

### Dropout

- **Q：解决的问题**

  **R：**解决神经网络过拟合

- **Q：训练和测试阶段有什么区别**

  **R：**训练阶段启动，测试阶段关闭。同时对于dropout我们在训练或测试阶段需要对其进行**rescale操作**，这是因为对于原本输出为x的神经元，我们以p的概率mask掉它之后，其输出的期望变成了(1-p)*x。因此我们为了确保神经元在训练和测试 阶段的输出期望基本不变，需要在训练阶段对其输出除以(1-p)或者在测试阶段乘以(1-p)。



### L1和L2正则化

- **Q：解决的问题**

  **R：**缓解过拟合问题，并且通过限制参数的大小缓解训练时的梯度问题

- **Q：为什么可以缓解过拟合问题**

  **R：**引入一个限制参数大小的惩罚项，防止模型变得过于复杂而失去泛化能力。

- **Q：相比于L2正则化，为什么L1正则化更容易产生稀疏解**

  **R：**从公式的角度，**L1正则化**式子中在参数0的位置求导会得到一个分段函数，其左右分别在靠近0时为-\lambda$$和$$\lambda$$，当这两个导数异号时，原损失函数将在0这个点产生极小值，那么我们在优化的时候就容易将损失函数给优化到这个点上。因此L1正则化更容易使一些参数变为0。

  ​	  从几何的角度，**L1正则化**的约束区域是一个菱形，其顶点位于坐标轴上。损失函数的最优解如最小二乘解）与菱形顶点相交时，某些维度（参数）被迫为零。



### Batch Normalization

- **Q：解决的问题**

  **R：**使得神经网络的训练过程更稳定，并且缓解梯度问题

- **Q：为什么**

  **R：**比如在训练模型时，我们希望输入的每个batch都具有相似的分布，所以会提前采取打乱和归一化的操作。同样的，对于神经网络的每一层来讲，我们也希望其输入具有相似的分布，因此我们采用BN限制输出的方差和均值。

  ​      对于梯度问题，BN会让输入激活函数的数据被限制在正态分布中，从而让大部分点远离梯度为0的区域。从而缓解梯度问题。

- **Q：训练和预测时有什么不一样**

  **R：** 训练时，对每一批的训练数据进行归一化，也即用**每一批数据**的均值和方差。

  ​       测试时，比如进行一个样本的预测，就并没有batch的概念，因此，这个时候用的均值和方差是**全量训练数据**的均值和方差。

- **Q：为什么不能和dropout连用**

  **R：造成预测时方差的偏差。**训练时dropout会改变每一层输出的方差，之后在进行BN时，采用的是**被改变后的输出的方差**。而在测试时，由于model.eval()，每一层的输出方差不会经过dropout修改，但是BN采用的方差仍然是**训练时的全局方差**。

- **Q：和LayerNormalization的区别**

  **R：**归一化的维度不一样，BatchNorm是对一个batch-size样本内的每个特征做归一化，LayerNorm是对每个样本的所有特征做归一化。**BN抹杀了不同特征之间的大小关系，但是保留了不同样本间的大小关系；LN抹杀了不同样本间的大小关系，但是保留了一个样本内不同特征之间的大小关系**

- **Q：为什么LN适用于序列模型**

  **R：**1. 序列任务的输入长短经常变化，BN针对所有样本进行归一化，容易受序列长度变化影响。而LN只针对单一样本，没有这样的问题。2.  LN保留样本特征之间的依赖关系，比如对于一个句子，其特征就是词语，词语之间的依赖关系是有意义的。



### 激活函数

- **Q：解决的问题**

  **R：**引入非线性因素，增加神经网络的拟合能力。

- **Q：主要有哪些**

  **R：**Sigmoid和Tanh —— 两端的导数趋近于0，导致梯度消失

  ​       Relu —— 输入为负时，梯度为0，导致神经元死亡

  ​       Leaky ReLu，Softmax等

- **Q：BERT和GPT中的激活函数**

  **R：**Gelu，其相比于ReLU的优点是：1. 处处可导；2. 在x<0的一定范围内避免梯度为0



### 过拟合

- **Q：过拟合的解决办法**

  **R：**从数据层面，增加数据量；从模型层面，剪枝，减少训练的时间，采用dropout，BN和正则化技术。



### 反向传播

每一层前馈网络：$$z_i=f(w_ix_i+b_i)$$

每一层参数的更新公式：$$w_i = w_i - \alpha \cdot dw_i$$

设i为最后一层，则：$$dw_t=\frac{d Loss}{dw_t}=\frac{d Loss}{dz_t}\frac{d z_t}{dw_t}=\frac{d Loss}{dz_t}w_tf'(w_tx_t+b_t)$$

设：$$Loss=(z_t-y)^2$$，则$$\frac{d Loss}{dz_t}=2(z_t-y)$$

因此：$$dw_t=2(z_t-y)\cdot w_t \cdot f'(w_tx_t+b_t)$$

因此参数更新：$$w_t = w_t - \alpha \cdot \left(2(z_t-y)\cdot w_t \cdot f'(w_tx_t+b_t)\right)$$



### 梯度爆炸和梯度消失

- **Q：产生原因**

  **R：不合理的激活函数和初始化参数。**反向传播计算梯度时时需要对激活函数求导，对于前面的层，在计算其参数的微分时会用到之后每一层激活函数导数的累乘，因此当激活函数的导数大于1或小于1时，其累乘的结果会呈现指数级增大和缩小，导致梯度爆炸或消失。

- **Q：解决方法**

  **R：**选择合理的激活函数；合理的参数初始化；残差网络；正则化；BN



### 优化器

#### 梯度下降：

- 批量梯度下降：对整个训练集的损失函数求梯度，找到全局最优解
- 随机梯度下降：随机选择一个样本，计算损失函数并更新参数
- 小批量梯度下降：每个batch的损失函数计算梯度

#### 动量优化

- **公式：** $$w = w + m$$;  $$m = \beta \cdot  m-\alpha \cdot d J(w)$$
- 和梯度下降的区别在于通过 $$\beta \cdot  m$$ 将过去梯度对当前的影响给累计起来，减少震荡加速收敛
- 越久远的梯度对当前影响越小，因为有$$\beta$$

#### RMSProp

- **公式：**$$w= w-\frac{\eta}{\epsilon+\sqrt{s}} \cdot dJ(w)$$; $$s=\beta s+ (1-\beta) dJ(w)\otimes dJ(w) $$
- 将过去梯度的平方和纳入考量，作为新梯度的分母的一部分
- 过去梯度平方和越大，则当前更新的量越小

#### Adam（动量+RMSProp）

- **公式：**$$w= w-\frac{\eta}{\epsilon+\sqrt{s}} \cdot m$$; $$s_t=\beta_1 s_t+ (1-\beta_1) dJ(w)\otimes dJ(w) $$; $$m_t = \beta_2 m_t-(1-\beta_2)dJ(w)$$

- 偏差修正：$$m=\frac{m_t}{1-\beta_1}$$, $$s=\frac{s_t}{1-\beta_2}$$

- **Q：介绍一下Adam**

  - 概念：**Adam（Adaptive Moment Estimation）**是一种基于梯度下降的优化算法，它结合了Momentum和RMSProp的优点，能够在训练过程中加速收敛并自适应地调整学习率。Adam的参数更新规则包括一阶矩估计，二阶矩估计和偏差矫正。
  - 一阶矩估计：通过累积过去的梯度来平滑梯度更新的**方向**：$$m_t = \beta_2 m_t-(1-\beta_2)dJ(w)$$
  - 二阶矩估计：通过累积过去梯度的平方来调整梯度更新的**学习率**：$$s_t=\beta_1 s_t+ (1-\beta_1) dJ(w)\otimes dJ(w) $$
  - 偏差矫正：一阶矩和二阶矩的初始值通常设为0。由于其计算方式，早期的估计值会偏向于0，导致低估了真实的梯度和梯度平方的均值：$$m=\frac{m_t}{1-\beta_1}$$, $$s=\frac{s_t}{1-\beta_2}$$

- Adam的优化版本：

  - **AdamW: **将权重衰减从梯度更新中解耦，解决了 Adam 中**权重衰减**与**学习率**耦合的问题。

  - **RAdam：**加入warmup机制，解决了 Adam 在训练初期由于方差估计不准确导致的收敛问题。同时在初期会切换为SGD with momentum。

    

#### Warmup学习率调度策略

- **Q：介绍一下Warmup**

  **R：在训练初期采用较小的学习率，一段时间后再采用预设的学习率。**因为训练初期，模型对数据缺乏理解，较大的学习率容易学到错误的方向；因此一开始应该采用较小的学习率，在训练一段时间，模型具备一定先验知识之后，再切换到较大的学习率。



### 损失函数

- **Q：回归损失函数有哪些**

  **R：MAE和MSE**。从鲁棒性的角度，MAE较好，因为MSE存在平方，放大离群点的影响；从稳定性角度，MSE较好，因为平方会缩小误差。同时MAE由于梯度为固定值，更难收敛。

- **Q：分类损失函数有哪些**

  - 合页损失：确保正样本和负样本的最高分数之间的距离

    - $$L=max(0,1-y\cdot f(x))$$
    - $$L=max(0,margin-pos+neg)$$

  - 交叉熵损失：衡量概率分布差异，预测分布和真实分布的差异

    - $$L=-\sum p(x) log~q(x)$$

  - KL散度：$$D_{KL}(p||q)=\sum p(x) log\frac{p(x)}{q(x)}=\sum p(x)\left(log~p(x)-log~q(x))\right)$$

    - $$-\sum p(x) log~q(x)+\sum p(x) log~p(x)$$

  - Focal Loss：解决分类问题中类别不平衡问题

    - $$L=-(1-y)^{\gamma}~log(y); ~when ~\hat{y}=1$$

    - $$L=-y^{\gamma}~log(1-y); ~when ~\hat{y}=0$$

    - 解释：假设目前的场景是负样本居多，那么模型会错误地把大量标签为1的正样本划分为标签为0的负样本，根据公式，当标签=1时，预测值为0的情况下损失函数会被乘以一个惩罚项。从而放大器影响。

      

# 面经问题汇总

- **采用了什么激活函数？为什么？**

  - Sigmoid：
    - 定义域内连续可导。
    - 输出范围在0-1，有助于数据标准化。
  - ReLU：
    - 因为ReLU输入为负时输出为0，有助于实现稀疏激活，减少参数之间的相互依赖，防止过拟合。
    - 和Sigmoid相比，能够避免在输入过大时产生的梯度消失。

- **逻辑回归LR采用什么损失函数？为什么不采用平方差损失？**

  - 交叉熵损失
  - 梯度问题：LR包含激活函数，而对平方差损失求导会存在一项为激活函数的导数，因此容易导致梯度消失和爆炸的问题。而交叉熵损失的导数和激活函数无关。
  - 凸函数：平方差损失为非凸函数，模型易陷入局部最优；而交叉熵损失为凸函数。

- **二分类模型如何处理多分类问题？**

  - 为每一个类别训练一个二分类器，用于区分该类别和其他类别。预测时选择分类器输出得分最高的类别。
  - 为每两个类别训练一个分类器。预测时所有分类器投票。

- **解释下什么是Embedding？得到Embedding的几种方式？**

  - Embedding将离散的数据映射到连续的向量空间（比如商品ID到商品embedding）。

  - 获得embedding的方式：

    - **矩阵分解：**将用户-商品的大小为mxn的交互矩阵，分解为mxk和nxk的两个小矩阵。其中k为每一个用户和商品的embedding。
    - **Word2Vec：**通过自然语言，借助CBOW和SkipGram两种任务来学习输入word到embedding的映射。
    - **Item2Vec：**通过物品序列来学习到物品的embedding。
    - **Node2Vec**：通过BFS和DFS来随机游走产生物品序列，将物品序列输入Word2Vec获得物品。embedding。
    - **基于预训练模型：**如BERT，Roberta等。

  - 如何衡量embedding的好坏：

    - 通过相似物品之间embedding的余弦相似度来评判。

    - 通过embedding在下游任务上的性能来评判。

      

- **什么是共享embedding和独占embedding？**

  - 共享embedding：同一套embedding应用在模型的多个地方，用于缓解数据不足导致的稀疏问题。（比如双塔模型，物品塔的物品embedding和用户塔的交互序列物品embedding是共享的）。
  - 共享embedding的缺点：不同目标在训练同一套embedding时可能相互干扰。
  - 独占embedding：比如用户点击Item ID序列、购买Item ID序列、收藏Item ID序列中，相同Item ID在不同行为中有不同语义要求，互不共享。



- **Word2Vec面经**
  - 介绍Word2Vec：利用训练语料中词与词之间的关系，通过CBOW和SkipGram两种形式将自然语言中的词语转换成词向量的形式。CBOW是给定上下文预测中心词，而SkipGram是通过中心词预测上下文。**CBOW相当于公共课，效率高；SkipGram相当于私教课，效率低。**
  - 两种加速方法：层次Softmax；负采样。
  - 层次Softmax：
    - 采采用哈夫曼树，将多分类问题转化为许多个二分类问题。
    - 哈夫曼树：给定n个权重作为叶子节点，构成的带权路径和最小的树称为哈夫曼树。
  - 负采样是怎么做的：给定一个词，滑动窗口内的上下文看作其正样本，在根据语料库中词语的出现频率在上下文之外进行采样获得负样本，从而加快计算速度。
    - 将更新所有负样本转换为更新5-20个负样本。
  - Word2Vec的缺点：未考虑词序，对新出现的词不友好。



- **Wide&Deep面经**

  ![img](https://pic2.zhimg.com/v2-2458d135a0a97e11b447b6ff7e740f57_1440w.jpg)

  - 介绍Wide &Deep：根据不同特征的特点将不同的特征（如商品价格，商品简介等），输入Wide或者Deep区域

  - Wide和Deep分别适用哪种特征：

    - Wide：线性模型，拥有”记忆“能力，适用和输出指标**强相关**的特征。比如CTR场景下商品的价格这类特征。还有就是根据先验知识，需要对现有特征进行特征组合才能获得的特征。

    - Deep：深度模型，拥有”泛化“能力，适用一些商品图片或者商品简介这类难以学习的**隐式特征**。

    - 能否去掉Wide：不行，因为纯Deep模型的记忆能力弱，效果依赖embedding质量，容易忽略一些强规则。

      

- **DeepFM面经**

  - 和Wide&Deep有什么不同：

    - 将Wide部分采用的线性模型替换为FM：

  - FM和线性模型的区别：

    - 线性模型：

      ![image-20250309204054638](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250309204054638.png)

    - FM：

      - 引入二阶交叉特征$$x_ix_j$$，表达能力更强。
      - 通过近似矩阵分解$$u_{ij}\approx \textbf{v}^T_i\textbf{v}_j$$，将二阶交叉权重的数量从$$O(d^2)$$降低到$$O(kd)$$

      ![image-20250309204158532](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250309204158532.png)

      

- **AUC (Area Under Curve)面经**

  - **假正率（FPR）和真正率（TPR）：**FPR标签为0的样本中被预测为1的比例；TPR标签为1的样本中被预测为1的概率。

  - **ROC曲线：**以FPR为x，TPR为y的曲线，其反映了在不同分类threshold下（FPR，TPR）数值点的连线。**threshold的取值为测试数据集中各样本的预测概率。**

  - **AUC：**ROC曲线下的面积。

  - **AUC的工业定义是什么**：AUC在工业上的定义是AUC反映了模型的排序能力，如果AUC=0.7，说明模型有70%的概率将正样本排到负样本前面。

  - **AUC的快速计算公式：**

    $$AUC=\frac{\sum (p_i,n_j)_{p_i>n_j}}{P*N}=\frac{\sum _{样本_i \in 正样本}rank_{i}-\frac{P*(P+1)}{2}}{P*N}$$

    快速计算：

    - 通过引入rank，直接确定大小关系
    - 已知某正样本的排序序号$$rank_i$$，则可知道其和所有（预测值小于该正样本的）样本组成的样本对（包含正负对$$PN_{i}$$和正正对$$PP_{i}$$）的个数为$$rank_i$$。
    - 则由当前正样本组成的正负对（正样本预测值>负样本预测值）的数量$$rank_i-PP_{i}$$
    - 对于每个正样本而言，$$PP_{i}$$的值未知，但是对所有正样本的$$PP_{i}$$求和，其值为$$\frac{P*(P+1)}{2}$$（等差数列求和）。

  - 推荐为什么用AUC，不用准确率？

    - AUC衡量排序能力，准确率无法衡量
    - AUC关注的点是“尽可能降低犯错的概率”，而准确率关注的点是“尽可能找到更多的正样本”。
    - **在推荐的场景下，相比于多给用户推荐几个他感兴趣的视频，避免给它推荐不感兴趣的视频可能显得更为重要一点，因此我们往往选择AUC指标。**

  - **F1-score和AUC的关系？**

    - F1分数：预测为1实际为1的比例（Precision）和实际为1预测为1的比例（Recall）的调和平均数
    - 相同点：都优化了Recall（TPR）
    - 不同点：AUC提减少犯错误率；F1提高预测正样本为正的可能性。

  - **AUC的缺点**

    - 没有关注模型预测的具体概率值，只关注排序。
    - 只考虑了正样本和负样本的排序，没有考虑正样本内部和负样本内部的排序。
    - 衡量的是多个用户推荐结果的全局排序能力，没有针对某一用户的个性化考量

  - **GAUC**

    - 将数据分为k个group，计算每个组的AUC，再加权平均
    - 权重是group的重要性权重

  - **离线AUC涨了，但是线上指标没有涨怎么办？**

    - AUC反应的是整体排序能力，而线上是对每个用户排序。因此考虑**更换指标为GAUC**。
    - 离线和在线的**样本空间不一致**，比如CVR任务。
    - **特征穿越**，使用了和label强相关的特征。


## DIN/DCN/SIM

- **DIN面经**

  ![img](https://pic4.zhimg.com/v2-2362e66a79c2e4c4372253de64f04221_1440w.jpg)

  - **介绍一下DIN？**

    - DIN主要用于用户行为序列建模，解决了传统Embedding-MLP架构将用户行为序列中商品ID进行简单的平均池化导致丢失用户兴趣信息的问题。DIN引入注意力机制，根据候选物品和用户历史行为序列的相关性，动态调整每个历史行为的权重。

  - **怎么计算相似度？**

    - 通过AcitivationUnit。首先将用户交互物品向量和候选物品向量进行交互，交互的方式包括向量内积，向量加和向量减，文章中选择了向量减。随后将该交互向量和用户交互物品向量、候选物品向量拼接，输入一个前馈网络层得到最终的相似度分数。
    - 为什么采用向量减？
      - 向量减用于衡量向量的差异性，而向量加和向量内积并不能对差异性进行有效衡量
      - 具体地，比如对于两件价格不同的衣服，采用向量加只能衡量两者总价值的多少，无法反映两件衣服的价格差值。如果采用向量内积，则对于100元和200元的衣服，可能其相似度是很高的，但是用户可能因为两种价格的差距对贵的衣服不感兴趣。

  - **DIN采用sum pooling**

  - **采用了什么激活函数？**

    - **Dice:** $$a_i (1-Sigmoid(BN(y_i)))y_i+ Sigmoid(BN(y_i)) y_i$$

    - PReLU: $$a_i (1-P(y_i))y_i+ P(y_i) y_i$$

    - **PReLU的阶跃函数存在两个问题：**1.PReLU的图像在x轴的位置受阶跃函数的影响；2.阶跃函数不连续的性质使得PReLU也不连续。因此Dice针对这两个问题进行了优化：1.通过BN将Dice函数图像在x轴的位置和所有x的均值关联，图像的胖瘦和方差关联。2. 将阶跃函数替换为Sigmoid函数，使其连续可导。

      

- **DCN面经**

  ![image-20250325215619421](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250325215619421.png)

  ![image-20250325215641961](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250325215641961.png)

  - **介绍一下DCN：**DCN是一种结合了**显式特征交叉**和**深度神经网络**的推荐系统模型。其核心目标是通过高效的交叉网络自动学习高阶特征组合，弥补传统DNN在特征交互上的不足。

  - **Cross Network：** $x_{(l+1)}=x_0 \cdot (W_lx_l+b_l)+x_l$

    

- **SIM面经**

  - **介绍SIM：**传统的DIN模型注意力层的计算量正比于用户行为序列的长度，因此DIN只能记录最近几百个物品，否则计算量太大，从而可能忽略长期兴趣。SIM模型保留用户的长期交互序列，并从这进行快速查找，找到k个物品输入注意力层来减少计算量，同时保留长期兴趣。

    同时，SIM还引入了时间embedding。

  - **如何查找？**Hard Search，根据候选物品的类别，保留类别相同的物品。Soft Search，在历史行为序列中采用候选物品作为quary，进行k近邻查找。



- **SDM模型（Sequential Deep Matching Model）序列召回**
  - 短期兴趣：最后一次会话；长期兴趣：过去一周内，不包含短期的会话
  - 短期兴趣和长期兴趣表征利用Gate进行融合——用户表征
  - 线上：获取用户的交互行为，输入模型拿到表征，对训练好的物品表征进行k近邻查找。




- **Youtube**

  ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/712d731fdfdc54e51ad616f8ac8e3b43.png)

  - **介绍一下YoutubeDNN：**
    - 提出了知名的推荐系统三段论：物品池，召回，和排序
    - **训练任务**：预测用户观看的下一个视频（多分类）
    - **样本构造**：
      - 正样本：用户完成播放的视频
      - 负样本：用户点击不感兴趣的样本，曝光一定时间但未点击的视频，用户快速划过的视频
    - **损失函数——Sampled Softmax**
      - 负采样，简单/困难负样本
        - 简单：随机负采样
        - 困难：被排序淘汰的样本
    - **为什么归一化？**
      - Rescale
      - 点积和cosine相似度等价
    - **优化方法：**负采样
    - **输入：**用户的观看序列，用户的搜索序列，用户的地理位置等特征拼接
    - **模型**：多层DNN，拿到用户向量，去视频向量矩阵（最后一个层的参数矩阵）中进行k近邻查找。输出k个视频。




- **常见的召回算法**
  - 第一类：协同过滤，包括ItemCF（给定物品A，推荐其相似物品B，物品的相似度根据交互过它们的用户来得到），和UserCF（给定用户，推荐其相似用户交互过的物品，用户的相似度根据其交互物品的重合度判断）
  - 第二类：向量召回，包括DSSM双塔，YoutubeDNN，采用word2vce等
  - 除此之外，还有其他类型的方法，比如基于FM和用户行为序列等等。



## **推荐系统多任务场景**

- **Share Bottom：**对于两个不同的任务使用相同的输入，并在输入层共享一个shared bottom，随后将shared bottom的结果输入各自任务的任务塔中。

  - **问题1，负迁移：**两个任务可能相关性低或者关系复杂，多任务学习可能会损害它们的性能。
  - **问题2，跷跷板：**两个任务可能相互冲突，提升一个任务的性能会降低另外一个。

- **MoE**：将shared bottom拆成若干个小型DNN，每个DNN称为一个expert，再由一个门控网络Gate控制每个expert对某个任务的参与度。

- **MMoE：**由MoE的一个Gate变成了为每个任务都设计一个Gate

- **PLE（Progressive Layered Extraction）：**在MMoE的基础上做三点改进：

  - 直接将MMoE中Expert部分分为**shared expert**和**task-specific expert**，防止复杂的任务关系带来的参数制约。

  - 提出**渐进式的分离策略**，即低层专家提取深度信息，高层专家分离task-specific参数。

  - 整体由下到上分为三路，两个任务各自有一个由task-specific expert组成的路，同时还有一个由shared expert组成的共享路。每一层中，task-specific expert接受来自shared expert的信息，同时shared expert接受来自所有task-specific experts的信息。

    ![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/3d209f9bfc898d7196b429a924ea1863.png#pic_center)

- **ESMM：**

  - **目的：**为了应对推荐目标的序列依赖性造成的样本选择偏差。样本选择偏差指在模型训练和推理阶段样本的分布不一致，比如针对CVR（转化率预估）任务。如果训练的时候的样本是**被点击的样本**，而推理时的样本是**全体曝光样本**的话，训练的样本只是推理样本的子集，因此一定程度上违背了机器学习独立同分布的假设。因此提出ESSM用于将CVR这种任务的训练样本从子集拓展到全部曝光样本。
  - 比如针对CVR指标，由于存在关系：CTVR = CTR * CVR，而CTVR和CVR的训练样本都是全体曝光物品。因此ESSM**通过这学习两个任务，隐式地来学习CVR任务。**
  - **模型架构**类似双塔，CVR和CTR任务各一个塔，塔底有一个共享层。最后CTR和CVR的分数融合得到CTVR分数。ESSM的损失函数只优化CTR和CTVR两个目标，从而间接优化CVR。

  ![ESMM](https://i-blog.csdnimg.cn/blog_migrate/b174858f27de74fa2e803d02e14ef159.png#pic_center)

- **软共享和硬共享：**

  - 软共享：多任务共享一部分参数，还有一部分不共享或选择性共享
    - MMoE
    - PLE
  - 硬共享：共享所有参数
    - shared bottom
    - ESMM

- **推荐系统多个打分如何融合？**

  - 线性加法，比如加权和

  - 指数乘法，不同指标的指数相乘

  - 带权指数加法，$$\sum (\alpha_i+w_iscore_i)^{\beta_i}$$

  - 带权指数乘法，$$\prod  (\alpha_i+w_iscore_i)^{\beta_i}$$

    

- **如何定义召回中的负样本？**

  - **简单负样本：**

    - 从全体物品中进行抽样，抽样概率正比于物品点击次数的指数
    - batch内负样本
  - **困难负样本：**
    - 之前被召回，但是被排序淘汰的样本
    - **常见错误：曝光未点击的样本只能用于排序**，因为召回阶段寻找的是用户**可能感兴趣**的物品，被曝光给用户的物品已经满足这一条件了，可能只能碰巧没有被点击。





- **LTR的Pointwise, Pairwise, 和Listwise**

  - Pointwise：二分类的任务，比如输入用户和物品，如果是正样本物品则输出标签为1，负样本标签为0。

    - 缺点是指考虑单个物品和用户的相关性，没有考虑物品之间的关系，因此无法实现准确的物品相似度排序。

  - Pariwise：核心思想是两两比较，模型会同时看到一个用户的正样本物品和负样本物品，然后在训练时鼓励正样本和相关性大于负样本。比如Triplet Loss这类损失函数。

    - 缺点是只考虑了物品两两之间的关系，和我们最终希望优化的整个列表的排序目标不相符。
    - **给出一个Pariwise的算法——RankNet**
      - 输入为用户和两个物品，计算用户和两个物品的相关性并通过sigmoid函数将**相关性的差值**转化成预测概率，然后通过交叉熵损失进行训练。
      - 问题：没有考虑排序位置的权重，通常我们更关心头部的排序而不是尾部

  - Listwise：模型会同时看到一个用户的正样本和多个负样本，在训练时鼓励正样本的相关性大于所有负样本。

    - **给出一个Listwise的算法——LambdaRank**

      - 关键思想：训练模型不一定需要直接优化损失函数，可以直接计算梯度即可优化模型的参数。

      - **绕开损失函数，直接对梯度进行定义，从而使得模型可以直接学习NDCG这类不可导的指标。**

        

- **如何解决长尾问题**

  - **流量监控：**在排序阶段对低曝光物品提升权重；推荐结果中强行插入低曝光物品，根据用户的交互动态调控；尾部物品保量，至少出现n次。
  - **在召回阶段：**为低曝光物品设计特殊的召回通道，例如基于内容标签。
  - **数据层面：**进行热门物品的欠采样，冷门物品的过采样。



- **召回的优化目标？**

  - 离线指标：召回率，命中率，覆盖率等

  - 在线指标：CTR，CVR等

    

- **NDCG指标？**

  - NDCG指标是DCG和IDCG两个指标的比值
  - DCG指标考虑每个物品的相关性，但是对于排序靠后的物品降低其影响
  - IDCG是DCG的理想情况（比如相关性越高越靠前），因此NDCG就是在衡量当前的DCG多大程度上接近理想的DCG。




## 冷启动面经

- **冷启动召回的困难？**

  - 双塔模型效果不好：缺少用户和物品的交互，没有优质的物品embedding，导致双塔模型效果不好。

  - I2I召回不可用。

    

- **冷启动阶段双塔模型有什么不同？**

  - 主要问题是**缺乏物品的embedding**

  - 可以利用现有**高曝光相似笔记**的embedding均值

    - 相似笔记：计算内容（文本、图片）的相似度

  - 设计多个召回池，比如1小时召回池，6小时召回池等。增加新物品的曝光机会。

    

- **物品和用户冷启动怎么解决？**

  - TTMALL冷启动

    - 冷启动候选池：将累计单量=0；累计pv<=5000；进入冷启动天数<一个月的商品筛入/保留在冷启池

    - 召回阶段：有单独的冷启动召回方案

    - 后续排序阶段：

      - 划分 基础保量 和 高潜保量 队列（高潜有用户点击）
      - 进行PID流量调控，对不同的队列使用不同的boost分数，施加给精排融分公式。并且会根据队列整体曝光pv占比实时调节boost系数。

      【boost是越大越好吗？不是，过量boost会导致冷启动商品积累大量负反馈，不利于后续自然流量分发】


  - 冷启动的主要评价指标
    - 从**作者侧**
      - **发布渗透率 (penetration rate)**：发布渗透率 = 当日发布人数 / 日活人数
      - **人均发布量**：人均发布量 = 当日发布笔记数 / 日活人数
    - 从**用户侧**
      - **新物品消费指标**：新物品的点击率、转化率
      - **大盘的消费指标**：用户**观看时长**，日活等

  - 物品冷启动：

    - Default
    - 基于内容的推荐
    - 基于相似物品的推荐
    - 小流量曝光，根据点击率动态调整曝光量

  - 用户冷启动：

    - 基于注册信息：比如用户的年龄、性别、地域等人口统计学信息。

    - 先给用户推一些排行榜中的热门内容，吸引互动

    - 根据用户的实时反馈更新推荐策略

      

- **RNN系面经**

  - **RNN为什么导致梯度消失？**
    - RNN通过BPTT进行反向传播，参数W的更新由**所有时间步中损失函数和参数W的导数之和**构成，总的时间步越大，最开始时间步的导数含有的累乘就越多，导致RNN遗忘起初时间步的信息。
  - **LSTM如何解决梯度问题？**
    - LSTM的细胞状态是通过**加法计算**得到的，使得累乘时激活函数的导数可能大于1。
    - **遗忘门**和**记忆门**可以调控LSTM对之前信息的记忆。
  - **GRU和LSTM的区别？**
    - GRU是LSTM的简化版本，提供更快的执行速度和相当的缓解梯度问题的能力。
    - GRU舍弃了细胞状态，采用**重置门**和**更新门**。



- **树模型面经**

  - **回归树和分类树的区别？**

    - 子节点不同，子节点为类别即分类树，为数值即回归树。

  - **CART回归树**

    - 遍历所有特征的所有取值，对输入进行**二分法**，逐个计算不同特征的值作为切分点的**平方误差**，选择平方误差最小的特征值作为切分点。

  - **CART分类树**

    - 基尼值越低，不纯度越高。

  - **Boosting**

    - 输入x计算$f_{m-1}(x)$

    - 计算残差$r_{mi}=y_i-f_{m-1}(x_i)$

    - 拟合残差$r_{mi}$学习一个回归树，得到$T(x;m)$

    - 更新预测值$f_m(x)=f_{m-1}(x)+T(x;m)$

    - 多个模型的结果求和

    - 每一步的优化目标：

      ![image-20250311004230421](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250311004230421.png)

      s是数据的切分点；$c_1$是$R_1$内部平方误差的最小值（所有切分方式计算的平方误差）。

  - **GBDT**

    - **使用一阶导数，将残差约等于损失函数的负梯度。**

    - 传统boosting采用的残差是平方差损失的一阶导数，而平方差损失对异常值敏感。因此GBDT直接采用一阶导数来作为残差。

    - **计算过程：**初始以目标的均值作为初始树的预测值，计算预测值和真实值的残差，以残差为目标，拟合一颗浅层树，将新树的预测结果添加到初始树。重复。

    - **目标函数**

      ![image-20250311010416416](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250311010416416.png)

    ![image-20250311010707281](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250311010707281.png)

    ![image-20250311010740542](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250311010740542.png)

    - **GBDT残差的表示是通过对损失函数一阶泰勒展开得到的**

  - **XGBoost**

    - **介绍一下Xgboost：**Xgboost是基于boosting策略的加法模型，采用**前向分布算法**进行学习，每次迭代都会新建一颗树拟合之前的残差。除此之外，Xgboost的特点是对损失函数进行二阶泰勒展开，同时加入正则项。

  - **Xgboost和GBDT的不同？**

    - 优化目标：Xgboost采用二阶泰勒展开，GBDT采用一阶
    - 正则化：Xgboost有，GBDT无
    - 缺失值处理：Xgboost可以自动学出节点的分裂方向，如果某个样本的特征值缺失，会被划入默认分类
    - 并行化：Xgboost支持特征维度的并行，因为其预先将每个特征按照特征值排序并存储，分裂时可采用并行查找。
    - **应用场景：Xgboost适用大数据，并且特征包含缺失值，且需要避免过拟合的情况。GBDT适用数据量小，速度要求低的情况。**

  - **Xgboost和LightGBM的不同？**

    - Xgboots采用贪婪预排序方法遍历样本寻找最佳分割点；而LightGBM通过直方图近似寻找最佳分割点。
    - Xgboost采用level-wise策略分割树节点，即每一层都对所有节点进行分裂；而LightGBM采用Leaf-wise策略分割树节点，即每一层寻找一个增益最大的节点进行分裂。

  - **Xgboost为什么可以并行训练？**

    - Xgboost支持特征维度的并行，因为其预先将每个数据按照特征值排序并存储为block，分裂时可并行计算分裂的增益。

  - **Xgboost防止过拟合的方法？**

    - 目标函数添加正则项
    - 列抽样：训练时只选取一部分特征
    - 子采样：计算不使用全部样本

  - **Xgboost如何处理缺失值？**

    - 在对特征k寻找最优分裂点时，不会对缺失该特征的样本进行遍历。会在最后将缺失特征的样本分配到左叶子节点和右叶子节点，都计算一遍选择增益最大的方法。

  - **随机森林和Xgboost的区别**

    - 随机森林基于bagging思想，Xgboost是boosting思想
    - 随机森林关注模型的方差，而Xgboost关注模型的偏差
    - 随机森林的树可以并行生成，Xgboost不行
    - 随机森林对异常值不敏感，而Xgboost敏感



- **Transformer系面经**

  - **Transformer**

    - **为什么要除以根号dk？**
      - 保证梯度稳定：因为Sigmoid激活函数在输入过大时导数为0，容易导致梯度消失的问题。因此为了防止其输入，即Q和K的乘积过大，一般会除以根号dk以保证梯度稳定。
      - 保证方差稳定：Q和K的乘积方差为d，QK/根号d的方差为1，因此可以稳定方差
    - **能否去掉FFN？**
      - 不能，首先是FFN为Trms提供了非线性拟合能力，去掉之和Trms退化为线性模型。
      - 不能，其次自注意力机制和FFN能起到互补作用，自注意力机制关注序列中每个位置之间的交互，不考虑具体的位置信息，捕获**全局特征**。而FFN独立处理每个位置的信息，不依赖序列性，专注于**局部特征**。
      - 不能，从参数的角度考虑。FFN的参数总和占据了Trms60%以上，去掉FFN显著降低了Trms的表达能力。
    - **为什么使用多头注意力机制？**
      - 采用多个不同参数矩阵的自注意力机制，捕获不同表示子空间的信息，增强模型的泛化能力。
    - **为什么Q和K使用不同的参数矩阵？**
      - 将Q和K投影到不同的子空间，增强模型捕捉不同特征的能力，提升模型的泛化性。
    - **为什么采用点乘计算attention而不是加法？**
      - 点乘用于捕获Q和K之间的相似度，从而反映不同元素之间的关联。而向量加法不足以反映这种复杂关系，可能导致模型学习能力下降。
    - **在计算attention scores时如何对padding进行mask操作？**
      - 在计算attention scores时，会将padding的位置置为负无穷。这样在应用softmax时，这些位置的结果会趋近于0，从而在最终结果中忽略掉padding位置的影响。
    - **介绍一下transformer的位置编码**
      - Transformer采用正弦和余弦函数的组合来生成每个位置的唯一编码，然后将这个编码加到对应的词嵌入上。位置编码能够利用序列的时序信息，因为transformer本身不包含处理时序信息的机制。
      - $$PE^{(i)}_{t}=sin(w_t t),~if~i=2k$$
      - $$PE^{(i)}_{t}=cos(w_t t),~if~i=2k+1$$
    - **transformer采用三角函数作为位置编码的好处？**
      - 由于三角函数的性质能反映不同位置之间的距离。
      - 根据三角函数的和差公式，对于任意偏移量k，**位置i+k处的位置编码可以由位置i处的位置编码线性组合得到**。
      - 位置i和位置i+k处位置编码的**点积可以反映两者间的距离**，点积正好是transformer在计算attention score的时候采用的操作。
    - **了解哪些其他的位置编码技术？**
      - 相对位置编码
      - 可学习位置编码
    - **Decoder的多头注意力有什么不同？**
      - 采用了掩码机制
      - 因为Deocder部分具有自回归的性质，因此为了避免当前位置的输入提前看到之后的输入，我们需要对注意力分数矩阵进行mask。
    - **Transformer训练的学习率如何设定？**
      - Transformer的学习率采用warmup机制，初期学习率较低，慢慢随着训练进行调整到最大值。
    - **LayerNormalization的作用？**
      - 减少训练时内部协变量的偏移（即训练时网络中间层数据分布的改变），稳定训练过程，加快收敛速度。

  - **BERT**

    - **介绍一下bert**

      - Bert全称是Bidirectional Encoder Representation from Transformer，是基于Transformer架构的预训练模型。核心思想是利用transformer的**Encoder部分**，通过**双向的上下文信息**来理解句子，从而捕捉语义关系。

    - **Bert的预训练任务有哪些？**

      - MLM：随机mask句子中15%的词，用无监督的方式根据上下文信息预测被mask掉的词。
      - NSP：选择句子对A和B，有50%的概率B在A之后，剩余50%的概率A之后是随机的句子，以学习句子的相关性。

    - **MLM任务的mask是怎样做的？**

      - 随机mask掉句子中15%的词语，在这之中，有10%的词语被替换为其他单词，10%的词语保持不变，80%的词语被mask。计算损失时只计算被mask掉的部分的loss。

    - **NSP任务的正负样本如何构造？**

      - 选择句子对A和B，有50%的概率B在A之后，剩余50%的概率A之后是随机的句子

    - **Bert的NSP任务采用哪个位置的输出做二分类？为什么？**

      - 采用[CLS]做二分类。因为self-attention的存在，[CLS]一定包含完整句子的信息。其次，自注意力机制在计算时，自身的权重是最高的，因此采用两个句子中任何一个都不客观。[CLS]本身没有意义，更纯粹。

    - **介绍一下Bert的输入embedding？**

      - Bert的输入为三个embedding相加：分别是token+segment+position。
      - Token embedding是输入文本进行tokenization之后，将[CLS]插入开头 ，[SEP]插入结尾，然后进行token embedding look up。
      - Segmant embedding只有0和1两个值，用于在NSP任务中区分不同的句子。
      - Position embedding是随机生成的可训练的位置编码。

    - **BERT处理长文本？**

      - 截断输入
      - 分段输入

    - **BERT如何处理未登录词？**

      - 采用wordpiece，将词语分为更小的子词单元。面对未登录词时，可以将其分为更小的子词单元来获得其embedding。

    - **介绍一下Bert的变体**

      - g**SentenceBert：****致力高效地生成句子的表示**。Bert计算句子的相似度需要将句子拼接同时输入模型，而SBERT采用两个共享参数的BERT，分别学习两个句子，并对bert的输出进行池化获得句子表征，最后通过向量操作计算句子的相似度。
      - **Roberta：**更大规模的训练语料，更大的训练batch，更多的训练时间。采用**动态掩码**机制并且**移除了NSP任务**。
      - **macBERT：**修改了MLM任务为替换成近义词，同时对于中文任务，会替换整个词语而不是一个字。

    - **有哪些微调方法？**

      - 全量微调
      - 部分微调
        - 冻结部分参数层
        - 分层学习率，embedding层学习率小，顶层学习率大
      - 适配器微调
        - 在每一层中插入adapter（FFN+残差），只更新adapter的参数

      

- **介绍旋转位置编码（RoPE）**

  - 旋转矩阵将词向量在复数空间中进行旋转，从而将位置信息自然地融入向量表示中。这种方法巧妙地结合了绝对位置编码和相对位置编码的优势



- **搜索、推荐和广告算法的区别**

  - **从目标来看**，搜索的目标是满足用户需求，推荐的目标是预测用户的潜在兴趣，广告的目标是最大化收益。**从算法输入来看**，搜索的输入是查询词和上下文，推荐算法是用户行为和物品，广告是用户画像和广告。从评估指标来看，推荐的指标主要是CTR和多样性等，广告的主要指标是商业指标比如CVR等。

    

- **TS项目**

  - **项目介绍：**该项目致力于实现跨平台的关键用户实体匹配任务，具体来讲，我们从3个互联网平台，对一些知名的用户实体的产出内容进行爬取。通过对这些信息进行编码获取用户实体的嵌入表征，随后通过设计模型实现实体匹配。

  - **数据集介绍：**从3个国内的互联网平台，对一些知名用户实体近三个月发布的视频标题进行爬取。

  - **数据预处理：**

    - 文本清洗：去除视频名称中的噪声，比如特殊符号等
    - 分词与编码：使用sentenceBert库分词并获得每个视频标题的嵌入表征，随后计算表征的平均值作为该用户的初步实体表征。
    - 构建数据集：重构为一个二分类问题，将来自两个平台，相同用户的嵌入表征拼接，打上标签1，同时将该用户和其他用户的表征拼接，打上标签2。

  - **数据集不平衡：**

    - 过采样：SMOTE：
    - 欠采样：Tomek Link：删除和正样本欧氏距离最接近的k个负样本
    - 其他欠采样方法：
      - 基于聚类的方法：对负样本进行聚类，选择聚类中心作为负样本
    - 其他过采样的方法：
      - 随机
      - Borderline Smote：

  - **模型架构：**

    - 整体采用双塔模型作为base架构
    - 在双塔的输出层之前，引入 cross-attention进行实体表征交互。
    - 采用RAdam+LookAhead优化策略进行优化。

  - **问题**

    - **介绍一下LookAhead：**

      - LookAhead的核心思想是通过**快速更新来探索局部最优解**，再通过**慢速更新来对快速更新的结果进行平滑和修正，使其接近全局最优解**。

    - LookAhead首先使用基础优化器进行k次**连续快速更新**，并记录快速更新的参数：$$\theta_{fast}$$

      - 随后，LookAhead进行一次**慢速更新**，并将快慢更新的结果加权平均：

        - $$\theta_{slow} = \theta_{slow} + \alpha(\theta_{fast} - \theta_{slow})$$
      - 之后，快速更新的参数重置为慢速更新的结果。

    - 介绍AdamW：

      - 将权重衰减项从梯度计算中拿出来，加在了参数更新的式子中。

    - **介绍一下SMOTE：**

      - 对于每个样本，寻找其k个最近邻样本。
      - 之后在k个最近邻中随机选择n个邻近点计算它们和当前样本的差值，再乘以0-1的缩放系数。
      - 将缩放后的差值添加到原样本的表征上，构建一个新的正样本。

    - **介绍一下对抗训练**

      - 在输入上进行梯度上升，在参数上进行梯度下降
      - **介绍FGM**
        - 首先对输入x进行前向传播，在反向传播得到嵌入矩阵的梯度g
        - 对梯度g进行scale得到误差项:$\epsilon* g/||g||_2$，添加到嵌入矩阵中
        - 再前向传播和反向传播，得到对抗训练的梯度，和第一次的梯度累加
        - 恢复嵌入矩阵，并更新参数

    - **介绍一下FocalNCE Loss：**

      - -**如何将Focal Loss从二分类拓展到多分类？**

        - 将二分类的Focal Loss公式中对正负样本的参数扩展到对所有类别进行逐类计算，使用多分类交叉熵作为基本损失，然后对交叉熵中每个类别的概率施加focalloss项。
      - $p_c = \frac{exp(x*y_c)}{\sum_j exp(x* y_j)}$
      - $ce = \sum^C_iy_ilog(p_i)=-log(p_c)$
      - $infonce = -log(\frac{exp(x*y_c)}{\sum_j exp(x* y_j)})$
      - $focal_{ce} = -\alpha_c(1-p_c)^\lambda log(p_c)$
      - $focal_{nce} = -\alpha_c(1-p_c)^\lambda log(p_c) = -\alpha_c(1-p_c)^\lambda log(\frac{exp(x*y_c)}{\sum_j exp(x* y_j)})$

    - **还有哪些用于样本不均衡的损失？—— Class-balanced loss**

      - 根据类别的样本数量的反比进行加权
      - $\frac{1-\beta}{1-\beta_c'}L(y,y')$

      

      

## **双塔模型面经**

- **双塔模型的缺陷：**用户特征和物品特征在输出层之前没有交互。
- **DAT（对偶增强双塔）**
  - 核心创新点是首先通过**Adaptive-mimic Mechanism**隐式地实现了两个塔之间的特征交互。其次，通过**Category Aligment Loss**解决类别不平衡的问题，
  - **Adaptive-mimic Mechanism如何进行特征交互？**
    - 为每个用户和物品新增一个**增强向量**，该向量和特征拼接 输入用户和物品各自的塔里。当物品为正样本时，通过**均方损失**来拉近物品塔输出的增强向量和用户塔输入的增强向量的表征距离，对于物品塔的输入增强向量，使用用户塔的输出增强向量来拉近距离。**该Loss只用来更新增强向量，而不是用户物品表征。**
  - **Category Aligment Loss如何解决类别不平衡问题？**
    - 计算主类别和其他类别间的协方差矩阵，降低类别间差距。



- **对抗训练**

  - **介绍一下FGM？**

    - FGM对抗训练的核心思想是在每个训练步骤中，计算输入数据相对于损失函数的梯度，并**沿着梯度方向添加扰动**，生成对抗样本。

    - 使用对抗样本和原始样本一起训练模型，更新模型参数。

    - 过程：

      - ```text
        1.计算x的前向loss、反向传播得到梯度
        2.根据embedding矩阵的梯度计算出r= \epsilon * g/L2(g)，并加到当前embedding上，相当于x+r
        3.计算x+r的前向loss，反向传播得到对抗的梯度，累加到(1)的梯度上
        4.将embedding恢复为(1)时的值
        5.根据(3)的梯度对参数进行更新
        ```



- **LightGCN**

  - **介绍一下LightGCN**

    - LightGCN是一种用于推荐系统的简化图卷积网络（GCN）。

    - 主要创新点在于，第一，通过去除传统GCN中的**非线性激活函数**和**特征变换矩阵**，仅保留邻居节点的信息加权聚合操作，从而降低了模型复杂度；第二对各层嵌入进行加权求和获取最终的用户和物品表征。

    - 聚合操作公式：

      - $e^{(k)}_u = \sum_{i \in \mathcal{N}_u}\frac{1}{\sqrt{|\mathcal{N}_u|}\sqrt{|\mathcal{N}_u|}}e^{(k-1)}_i$

      

- **介绍一下谱聚类**

  - 拿到邻接矩阵：W

  - 计算拉普拉斯矩阵：$L=I-D^{-\frac{1}{2}}WD^{-\frac{1}{2}}$; $D_{ii} = \sum_{j} W_{ij}$

  - 对拉普拉斯矩阵进行特征分解，选择前k个最小的特征值对应的特征向量，构成特征向量矩阵U

  - 构建低维表示：将特征向量矩阵 U的每一行作为数据点在低维空间中的新表示。

  - 聚类：对低维空间中的新表示使用聚类算法（如K-means）进行聚类，得到最终的聚类结果

    

- **如何自适应调节多任务学习的权重？**

  - **基于任务不确定性：**引入额外的参数代表任务的不确定性：$$\frac{1}{2\sigma^2_t}L_t+log\sigma_t$$
  - **基于梯度归一化(GradNorm):** 通过调整各任务的损失权重w，使得各任务的梯度范数相近。
    - 对共享参数层，计算每个任务损失函数的权重w的梯度，加L2范数
    - 所有任务的梯度范数的均值作为基准
    - 最小化每个任务的梯度和基准的差异



- **为什么分类问题不用MSE作为激活函数？**
  - 分类标签在欧氏空间没有实际意义，任务不匹配。
  - MSE在反向传播时，梯度公式中包含激活函数的导数。假如采用的是sigmoid函数，那么在分类任务的场景下，其输出为1和0时对应sigmoid的梯度很小，极易造成梯度消失的问题。



- **如何对负采样进行校准**
  - **基于采样比例进行调整**
    - 比如对于点击率预估任务，真实的点击率是正样本数目除以正负样本数目之和，而负采样之后，负样本的数目变为原来的alpha倍，那么实际预估的点击率的分母中，负样本的数目就变少了，导致模型预估的点击率偏大。我们只需要联立刚才提到的两个公式就可以求出真实预估值和实际预估值的关系，代进去即可。



- **MLE和MAP有什么关系？**
  - MAP是在MLE的基础上添加了参数的先验概率。在参数从均匀分布采样的情况下，MAP会退化为MLE。



- **NCE Loss**

  - 将采用softmax的多分类问题转换为一系列二分类问题

  - 原先多分类问题：用户对全部物品的偏好概率分布

  - 现在的二分类问题：用户和某个物品是否构成正样例？

  - **过程：**在给定上下文x的情况下，用p(y|x)采样k次得到负样本。

    

- **NCE和NEG损失的区别**

  - NCE理论完备，主要是通过对真实数据和依据概率分布采用的噪声进行二分类，从而学习真实数据和噪声数据分布的差异。
  - NEG不基于概率生成模型，而是直接采用负样本。




- **MRR和NDCG的不同**
  - MRR只关注第一个正样本的排序
  - NDCG关注整体top-k列表的排序



- **介绍一下IJCAI的论文**

  - 领域：会话推荐，训练目标是根据匿名用户的交互序列预测其下一次交互物品，评测指标是针对训练出的用户表征，向其推荐top-k个物品，并计算Recall、HitRatio等指标。

  - 研究背景：

    - 会话推荐面临用户档案信息缺失的挑战，用户表征仅能基于交互序列生成。
    - 交互序列中的物品**不一定反映当前偏好**，准确挖掘**多种用户意图**是获取精确用户表征的关键。

  - 现有方法仅通过滑动窗口捕捉**短期时间维度**的意图，忽略了用户下一次决策的**长期依赖性**。除此之外，现有工作还忽略了**对当前用户意图的挖掘可以结合来自其他大量用户的意图信息**，即空间中的大尺度意图。

  - 因此，我们的创新点是：

    - 首先对交互序列中隐藏的**用户意图进行层次化分解**，即用户意图可以分为时间维度的意图和空间维度的意图，进一步我们将时间意图分为长期意图和短期意图，空间意图分为小尺度意图和大尺度意图，比如购买苹果15和购买电子产品。
    - 其次，我们提出，用户的**长短期意图往往是互斥的**，即相互会产生干扰，比如对于一个电子产品爱好者，他过去的交互物品可能是手机电脑这种电子产品，但是最近由于天气变化，其交互物品变成了衣服和围巾。那么这种情况下，长短期意图在获取用户最终表征的过程中是互斥的，因此应该从原始序列中对其进行解耦，并分别学习。
    - 除此之外，我们还提出用户的**大/小尺度意图是相容的**，比如购买手机和购买电子产品，本质上是相关的意图。因此我们可以在学习用户的小尺度意图的同时，融入大尺度意图的信息来对其进行增强。

  - 具体的方法层面：

    - 首先我们提出了一个**长短期意图解耦模块**，用于从交互序列中分离出能代表用户长短期意图的物品。

      - 简单来讲就是，针对一条交互序列，我们首先用物品的聚类中心来替代每一个物品，可以理解为这是每个物品的语义类别。随后我们指定了长期类别和短期类别，长期类别是该序列中出现次数最多的语义类别，短期类别是该序列中最后一个语义类别。（比如序列的最后一个物品是衣服，衣服的语义类别可能是穿搭，那么穿搭就是该用户的短期意图）随后我们分别将其和原始序列进行两次余弦相似度计算，并对结果进行硬过滤以分别获得能代表用户长短期意图的两个交互序列。

    - 随后，我们针对长短期意图序列，分别设计了特征变换网络对其进行学习。

      - 对于长期序列，由于其包含的物品较多，且关系较为复杂。我们采用图结构对其进行重构，采用图神经网络进行特征聚合，最终通过softattention机制得到用户的长期意图表征。
      - 对于短期序列，其往往包含的物品较少，且较为连续，因此我们采用添加了位置编码的Transformer-Encoder对其进行聚合，并最后一个输出作为用户的短期意图表征。
      - 长短期意图表征通过门机制进行融合，使得模型可以**自适应地调节长短期意图在最终用户表征中占据的比重**。

    - 除此之外，我们认为仅仅通过交叉熵损失拉近用户真实点击物品的表征距离并不能学习到具备泛化性的用户表征，因为**某一个物品表征仅仅用户小尺度意图的体现**。因此，我们还设计了额外的对比学习任务，将用户真实点击物品的语义类别作为正样本，batch内其他物品的语义类别作为负样本，以将大尺度意图信息结合到当前的用户表征中。

      

- **介绍一下ICSIM的论文**

  - **去噪：**过去工作大多采用**数据层面的去噪**（对输入去噪），加剧了数据稀疏的问题。
  - 提出了**特征层面的去噪方法**：在GAT的聚合过程中，对边权值进行稀疏化。稀疏的依据是节点之间的相似度，采用的具体方法是softmax的改进版——$\alpha$-entmax。

  

- **介绍一下第二篇论文**

  - ·这篇论文主要关注长尾推荐领域，解决的问题是过去工作往往**以损失准确性为代价换取长尾性能的提升**。

  - 具体来讲，过去的工作仅仅关注如何引入尾部物品，没有考虑尾部物品是不是全部应该被引入（因为尾部物品存在大量**噪声或低质样本**），导致准确性下降。

  - 因此，我们提出的核心思想是：**对尾部物品需要有选择性地引入。**选择的标准就是，引入的尾部物品需要尽可能分布在当前用户的目标意图之内。

  - 因此，首先我们提出了**混合意图建模**。通过通过**语义关联性**（即物品是否属于同一类别）与**共现模式**（即跨用户高频率共现的类别组合）两个维度，构建**物品→意图**的映射网络。

  - 基于混合意图，我们进一步构建**意图→用户**的映射，定义用户下一交互物品所属的混合意图为**目标意图**，其余意图视为噪声意图。模型仅引入目标意图内的尾部物品，确保增强数据与用户真实需求对齐。

  - 具体应该如何实现呢？我们提出了两个约束，即长尾约束和准确性约束，分别致力于提升长尾和准确性指标。

    - 对于长尾约束，我们从表征学习的角度出发，希望提升那些属于用户目标意图的尾部物品和当前用户的相似度（相对于头部物品来讲）。具体来讲，我们希望设计一个损失，其能最小化当前用户表征到期目标意图包含的所有物品表征相似度分数的方差。方差的降低意味着相似度分数的波动变小，从而平衡头部和尾部物品的推荐概率。

    - 对于准确性约束，我们希望降低噪声意图对用户推荐的干扰，即降低所有噪声意图形成的分布和当前用户表征的相似度。由于分布需要均值和方差来同时确定，因此我们对均值和方差都提出了限制。具体来讲，我们希望设计一个损失，其能最小化当前用户表征到所有噪声意图表征相似度分数的均值，相当于把整体噪声给拉远，同时抑制这些相似度分数方差的上限。

    - 随后，我们结合这两个约束，提出了Intent Constraint Loss即意图约束损失：

      ![image-20250318001600240](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250318001600240.png)

  - **如何降低长尾约束的复杂度？**

    - 因为我们之前提出的长尾约束，需要计算用户表征到属于其目标意图的所有物品表征的相似度，再降低所有相似度分数的方差，因此假设物品数量为N，表征维度为d，时间复杂度就是O(Nd)。而我们发现，这一过程可以理论等价于降低用户表征到目标意图表征的相似度，因此变成了O（d）。

      

- **如何解决长尾问题**

  - **流量监控：**在排序阶段对低曝光物品提升权重；推荐结果中强行插入低曝光物品，根据用户的交互动态调控；尾部物品保量，至少出现n次。
  - **在召回阶段：**为低曝光物品设计特殊的召回通道，例如基于内容标签。
  - **数据层面：**进行热门物品的欠采样，冷门物品的过采样。



- **Item2Item如何计算相似度**
  - 基于协同过滤（用户交互）：余弦相似度（分子是同时交互过物品a和b的用户数量，分母是各自的交互用户数目乘积再开方）
  - 基于物品内容：BERT获取物品嵌入



- **逻辑回归为什么要离散特征**
  - **增强异常数据的鲁棒性：**比如我们对年龄大于50的人群划分为1，小于50的人群划分为0，这个时候如果有一个错误数据比如年龄为500，那么模型依然不会受到影响。
  - **增强模型的表达能力：**离散特征相当于把某一范围的特征值都变成某一固定的值，相当于对每个值都乘以一个不同的系数。整体来看相当于为后续的LR模型引入的非线性因素。





- **大模型在推荐系统中的应用**
  - 大语言模型增强的推荐系统：
    - 获取用户和物品的高质量embedding
    - 对用户和物品的缺失信息进行补全
    - 解决推荐系统的长尾问题
      - 输入端：embedding
      - 输出端：重排
  - 大语言模型为中心的推荐系统：
    - 指令微调
    - 交互式推荐
  - 大语言模型设计个性化推荐系统：
    - 个性化参数微调：iLoRA
    - 可解释的推荐系统，比如针对推荐结果生成自然语言解释，允许用户通过自然语言反馈调整推荐结果



- **介绍LORA**
  - 基于intrinsic dimension理论，预训练模型的参数矩阵在存在一个极小的维度，微调它和在全参数空间中微调能起到相同的结果。
  - LORA认为，参数更新过程中也存在一个intrinsic rank，优化这一部分可以近似等价于优化全参数矩阵。
  - 固定PLM的参数，只训练低秩分解矩阵A和B，将A和B的乘积和原始参数矩阵累加。
  - A是随机初始化，B是0初始化，确保训练开始时dW是0矩阵。



- **各种训练方式**
  - CPT（Continued Pre-Training）：继续在大规模无监督文本数据中进行自监督训练，增强领域适配性。
  - SFT（Supervised Fine-Tuning）：使用人工标注的输入-输出对，进行训练。
  - RLHF（RL from Human Feedback）：结合人类反馈训练奖励模型（RM），然后使用强化学习优化语言模型的输出质量。
  - DPO（Direct Preference Optimization）：结合人类反馈，通过奖励模型指导训练。DPO直接优化偏好，不需要强化学习。

# 场景题

- **冷启动推荐的物品用户不喜欢怎么办？**

  - **精准匹配冷启动用户**：

    - 根据冷启动物品的类别标签，推给对该类别感兴趣的用户

    - **新用户**和**低活用户**对推荐结果的敏感度较低，可以作为新物品的推荐目标

      

- **AB实验如何选择实验组和对照组**

  - 比如新策略GNN的某个参数（比如层数）有三个候选值

  - 将用户ID用哈希映射到一定区间的整数，对其随机分为十个桶，每个桶有n/10个用户

  - 其中三个桶作为实验组，一个桶作为对照组（不采用新策略）

    

- **多个部门都想做AB实验，应该怎么做？**

  - 分层实验：同层互斥，不同层正交

  - Holdout：保留 10% 的用户，完全不受实验影响，可以考察整个部门在一段时间内对业务指标的贡献

  - 推全：新建一个推全层，和其他层正交

    

- **在AB实验中，希望尽快推全，但是有些指标有滞后性，应该怎么做？**

  - 采用**反转实验**，也就是在推全的用户层在开辟一个旧策略的用户桶，持续观察该用户桶和其他用户的指标差距。

  

- **双塔模型的最后一层为什么要做L2Norm+温度系数？**

  - L2Norm的作用：

    - 统一用户和物品嵌入的scale。
    - 使得计算余弦相似度等价于计算点乘。在利用点乘计算用户物品相似度的情况下，softmax+交叉熵损失可以等价为一个margin为2的（N-1）Triplet Loss。2就决定了正负样本的差距。
    - 将2换成超参数，就可以人为调控正负样本的差距，这个超参数我们把式子推导回去可以发现，它就是双塔中的温度系数。

  - 温度系数的作用：

    - 调节正负样本的差距.

      

- **离线AUC涨了，但是线上指标没有涨怎么办？**

  - AUC反应的是整体排序能力，而线上是对每个用户排序。因此考虑**更换指标为GAUC**。
  - 离线和在线的**样本空间不一致**，比如CVR任务。
  - **特征穿越**，使用了和label强相关的特征。

  

- **低活跃度用户可以过双塔吗？如何做？**

  - 低活用户的特点：行为少，特征少，embedding质量低。

  - 可以，但是效果可能不如基于规则的策略，比如基于热门度。

  - 需要增强用户的嵌入表征，

    - 比如利用人口统计学信息比如年龄等补充用户的画像。
    - 找到其相似用户，对embedding进行聚合

    

- **介绍有哪些序列建模的模型**

- 根据我的经验，可以大致分为三类：

  - **Pooling-based：**

    - Embedding-MLP
    - youtubeDNN

  - **Attention-based：**

    - DIN
    - SIM
    - BST（Behavior Sequence Transformer）
    - AutoInt
    - DSIN

  - **Sequential-based**

    - GRU4Rec

    


- **新增一路召回，离线指标涨，但是在线指标几乎不变，为什么？**
  - 说明新增的召回通道没有发挥作用
  - **如何评估召回通道的作用？—— 独占曝光占比（PVR）**
    - 最终曝光的物品只来自某一召回通道的占比，可以视为该路的贡献
    - 用PVR评估各路召回的贡献，去掉贡献低的通道
  - 问题的本质：**边际效应**
    - 一维增加召回通道不一定带来稳定提升。
    - 线下实验时，评估召回性能通常会做独立性假设，即假设只有该路召回时的指标提升。
    - 而在线上时，当前通道召回的物品可能已经被之前的通道召回。



- **多路召回通道的结果如何进行融合？**

  - **简单去重**

  - **加权排序：**为每个通道分配权重，对物品的得分进行加权求和，再排序，最后做截断。（通道的权重如何确定？机器学习方法离线计算）

  - **分层截断：**按照相关性从各个召回通道取出前Top-k个结果，保证高优先级的物品被曝光。

    

- **大模型在个性化推荐的应用**

  - **iLoRA**：
    - 传统方法采用单一的LoRA模块对所有用户行为进行微调，忽略了个性化差异。从而导致负迁移问题。
    - 创新点：将LoRA的AB矩阵拆分为多个子矩阵，即多个专家，每个专家对负责某一类的用户行为模式，对于某一输入序列，通门控网络对专家权重进行调整。



- **One Epoch问题**
  - 原因：在embedding-mlp架构下，embedding层具有很强的稀疏性导致其收敛的速度和mlp层不一致。在第一个epoch之后，embedding层已经基本完成收敛，而mlp层还在继续收敛，从而导致过拟合。
  - 解决方法：
    - 论文中的方法：训练每一个epoch之前重置embedding层
    - Early Stop
    - 流式训练，增量更新。即实时收集线上的数据，增量更新embedding层的参数，冻结mlp层。



- **向量召回和策略召回的优缺点是什么，怎么解决向量召回的性能问题**
  - **向量召回**通过将用户和物品映射为向量并计算相似度实现召回
    - 优点：捕捉用户物品之间的深层次特征（如语义关联），支持复杂交互模式挖掘，并具备较强的泛化能力。
    - 缺点：依赖训练数据，计算复杂度高。且可解释性弱。
  - **策略召回**依赖人工规则或统计方法（如推荐热门物品和协同过滤）
    - 优点：可解释性强，计算效率高。
    - 缺点：依赖经验，对复杂的场景缺乏泛化性。
  - 离线计算，提前储存用户和物品的embedding。采用一些降维的算法，降低embedding的嵌入维度。



- **精排把粗排结果当成特征会有什么问题**
  - 也就是在精排的输入中利用了粗排对物品的排序和相关性分数的信息。
  - 问题：
    - **特征泄露**，因为相关性本身是精排模型要预测的目标。
    - **放大粗排的偏差**，粗排是低精度筛选，可能有偏差。精排如何依赖其结果，进一步放大偏差。
    - **削弱精排的价值**，推荐系统的整体质量取决于粗排的质量。



- **设计一个新闻推荐系统**

  - **召回：**从百万级的新闻库中快速筛选出数千条候选新闻，覆盖用户的潜在兴趣。—— 多路召回
    - **热门召回：**基于时间衰减权重的热门新闻池（1天/7天/30天）
    - **协同过滤召回：**UserCF、ItemCF
    - **内容召回：**关键词匹配+向量召回（双塔模型）
    - **冷启动召回：**：新发布的新闻进入独立池，按照作者发布内容的历史质量（比如该作者历史平均的CTR指标）分配初始的流量。
    
  - **粗排：**轻量级的模型进行快速筛选
    - 树模型：LigthGBM
    - COLD三塔模型：用户塔、物品塔、交叉塔
    
  - **精排：**使用深度模型
    - Learning to Rank的三种范式：Pointwise、Pairwise和Listwise
    - Listwise：LambdaRank
    - 对用户的历史点击序列进行建模：DIN、SIM
    
  - **重排：**
    - MMR
    
    - 冷启动物品强制曝光
    
      
  
- 召回和排序的建模有什么不同？

  - 召回：基于双塔的召回，在给定user embedding前提下，找到和其相似度最高的item embedding。即建模 argmax p(item | ue)
  - 排序：是target-aware建模，将待预测的item需要和用户历史行为提前做交叉，最终预测ctr/cvr等指标


# 更多补充

## TTmall推荐链路

预过滤：根据预先设置的chennel/region/language等在进入召回前提前过滤一部分商品

召回：
	⁃	本地召回：不走rpc，根据user和context消息召回
	⁃	外部召回：走rpc
		⁃	倒排召回（i2i）：根据用户历史序列计算trigger，利用trigger去倒排中检索item。可以同时用多个trigger拉取多个物品list称为倒排链。倒排链通过蛇形merger合并。
		⁃	向量召回：用户和物品embedding
			⁃	用户协同：ufs计算用户embedding，ANN实时检索最相似的user/item embedding
			⁃	单ctr/cvr预估模型
			⁃	Mtl模型：平衡多目标 — grad norm
			⁃	多兴趣模型：MIND / 物品1/2级类目作为不同粒度的用户兴趣，用于替换交互序列中和物品塔中的物品。
		⁃	近线召回：离线预计算user的排序结果，取前200个存入redis。线上serving时，对该user的多路召回结果靠后的商品进行替换。保证这些高相关商品进入排序候选。

召回到粗排之间：
	⁃	PreMerge：召回结果预合并
	⁃	Filter：商品取正排，进行过滤
	⁃	Merge：多路召回结果进行蛇形合并

粗排：
	⁃	启动条件：进入粗排的商品数大于给定阈值
	⁃	三类粗排模型：
		⁃	mtl：
		⁃	dfo：以一些负反馈信号（差评率等）作为训练目标
		⁃	Cascade：将精排胜出作为正样本，未胜出作为负样本，学习精排通过率。保持粗精排一致         

精排：
	⁃	三类精排模型：
		⁃	mtl：更复杂，有MHA、DIN、DCN、LHUC等
		⁃	行为序列：短期（近30条）/长期（近1000条，SIM硬search）
		⁃	dfo：以一些负反馈信号（差评率等）作为训练目标
		⁃	Cascade：将精排胜出作为正样本，未胜出作为负样本，学习精排通过率。保持粗精排一致性。
	⁃	ValueTree融分
		⁃	根据精排模型的预估值（ctr、cvr、dfo等），结合来自booster的boost分数，计算精排的融合分数。
		⁃	combine_score (ctr+cvr) * dfo_mutiplier (1+alpha*dfo_pre) * boost_score

产生样本 - joiner
	⁃	精排选出的商品作为Feature流，先存入cache，设置ttl
	⁃	商品曝光给用户之后，根据用户的点击/购买行为产生UA流，存入cache，设置ttl
	⁃	Feature的ttl到达之后，根据UA和Feature进行Join，Join上则为正样本，没Join上为负样本，dump到存储空间。

重排：

- 先调用generator（MMR）产生重排序列，再进行规则重排

   -    已选池S，候选池R，计算R中每个物品的score
        -    $MR_i  = 一个权重 * 精排分 - （1-权重）* 物品i和已选池S中物品的的最大相似度$

混排：
	⁃	将product、live、video三个体裁的结果混合

额外: 
	⁃	召回归因
		⁃	Snake merge优先归因：某商品在召回结果merge的过程中，第一次来自哪个召回，就归因到该召回
			⁃	特征：衡量当前召回的绝对价值
			⁃	劣势：受到recall weight的影响，recall weight大大召回会优先抢占高质量商品的归因权
		⁃	Snake Merge全部归因：snake merge扫到的商品被归因到当前召回，一个商品可以被归因到多个召回
			⁃	特征：衡量当前召回的兜底价值
	⁃	某路召回的pv涨，说明什么？
		⁃	该召回被后续链路认可，价值更高。至于具体发挥的价值，通过召回归因来判断（独占/非独占）。

## TTmall的i2i召回

- 概括：根据用户历史序列计算trigger，利用trigger去倒排中检索item。可以同时用多个trigger拉取多个物品list称为倒排链。倒排链通过蛇形merger合并。
- 缺点：无法考虑user侧的一些side info，并且无法考虑除item id之外的item信息
- **trigger如何选择** -- 基于用户的feed历史
  - 按照用户行为：加购、收藏、下单、支付、搜索等
  - 进一步按照时间划分：拉取长短期浏览历史
  - 按照场景划分：拉去各个场景的浏览历史
- item的embedding怎么取？-- u2i模型dump的embedding

## 长序列建模


⁃	**第一代序列建模方案**
	⁃	基础方案
		⁃	序列降噪：傅立叶变换将时域信息转换到频域，使用一个可学习的全局滤波器进行reweight【电商场景用户复购率显著提高】
		⁃	多场景建模：基于DIN，场景的eb和目标物品eb结合生成不同的query，不同的query对不同seq item进行target attention
	⁃	长序列方案 （问题：损失部分序列信息换取效率）
		⁃	Search长序列：SIM
		⁃	Pretrain长序列：Trms双塔对2000长度的用户序列预训练得到UE，再迁移到下游任务 
⁃	**第二代序列建模方案**
	⁃	长序列建模
		⁃	输入层：
			⁃	Global Token：和序列拼接用于信息整合。（主要为TargetItemToken、CLS Token、UIDEmbedToken等。）
			⁃	Token Merge：将相邻的k个token合并 【add时：显存开销1/k^2；concat：1/k】
			⁃	RoPE位置编码：核心创新在于通过复数域的旋转操作将位置信息融入词嵌入，而非传统的拼接或相加方式。它将词嵌入向量映射到复数空间后，用与位置相关的旋转矩阵对其进行旋转，使向量角度随位置变化、模长保持不变 —— 这种设计既让位置信息与语义信息有效解耦，又能让模型精准区分不同位置的 token。
		⁃	模型层：
			⁃	基于qkv的压缩
				⁃	对Query进行压缩
					⁃	Perceiver：对query进行压缩——初始化K个可学习的聚类中心；crossattn将序列信息蒸馏到聚类中心；selfattn捕捉聚类中心之间的高阶关联
					⁃	Decoder：Perceiver基础上的进一步简化——只使用Global Token作为query
				⁃	对KV进行压缩
					⁃	Sparse Attention：激活函数entmax/滑动窗口只计算对角线右边k个物品的attentionscore
					⁃	Flash Attention：
					⁃	MoBA Attention：K和V划分为k个Block，并通过MoE选择前k个block
			⁃	基于qkv的预存储
					⁃	kv-cache：对每个用户，序列都是自增的，因此每次serving可以复用之前的结果
					⁃	【流式训练kv-cache会失效，因为上一次请求之后模型的参数已经改变】
					⁃	如何解决：先批式训练kv，在流式训练时冻结参数
⁃	训练阶段
	⁃	Progressive Learning：短序列预先训练一个k层模型，随后把这个k层模型进行复制和放大，再继续用长序列训练



## 召回模型复杂化（召回突破双塔）

### Deep Retrival

![img](https://picx.zhimg.com/v2-c7dd922a95800be5ffd7df39c25525b9_1440w.jpg)

### 二向箔召回

![img](https://pic3.zhimg.com/v2-ade52983e02192d5830223703a11ab3a_1440w.jpg)

- 差异

  - **二阶段方法**：先训练模型，再检索；
    - *核心问题*：高效ANN检索需要依赖user/item embedding内积，因此模型的训练结构必须为双塔，直接去优化user/item 的embedding内积，从而统一目标。
  - **一阶段方法**：训练模型 和 构建检索过程 同时进行
    - *核心问题*：虚拟节点不能利用side info；EM训练慢
  - **二向箔**：先训练模型，再基于训练结果构建 HNSW检索；检索时不采用内积而是模型打分。

- TLDR：用模型打分替代传统内积，同时为了减少计算量（serving时避免每一个item都和user输入模型打分），采用了HNSW来近似搜索相关的item，然后和user一起打分。

- 整体流程

  - ***训练***

    可以采用任意复杂模型训练；训练完成之后，通过随机采样构建HNSW，根据item和item的L2距离构建邻居

  - **serving**

    直接通过HNSW对user进行从上到下的检索，每一层对user-item进行打分，打分可以采用任意深度模型

- 模型侧改进：Target Attention

- 索引改进：采用HNSW构建索引

  - 大部分item构成一个个的小世界，小世界之间由路径连接
  - 一层一层往上，每一层更少的item节点

### Streaming-VQ

![img](https://pic2.zhimg.com/v2-f2bdaefb2e4ac15471072a3444074cc5_1440w.jpg)

- 主要是为了解决**即时性**和**索引平衡性**的问题

- 即时性

  每进入一条样本，就能得到索引-item的对应关系，并且存储起来。因此可以实时地更新

  - 因为索引embedding依赖EMA实时更新，而HNSW的embedding是固定的

- 平衡性

  VQ天然保证平衡性



## 多兴趣召回模型 

### **Mind**

![img](https://pic1.zhimg.com/v2-e679d7af95b1c1c87e1c47e3b82285ea_1440w.jpg)

- 针对 “多兴趣” 场景，通过动态路由机制（如胶囊网络的路由算法）从用户历史行为中学习并生成多个独立的兴趣向量，每个向量对应用户的一个兴趣维度，能同时匹配不同类型的候选物品
- 缺点：多加head才能换取指标提升，但是ROI会负	

### Trinity

- 短视频的多兴趣和商城有什么不同？

  - 商城中确定用户兴趣的条件更苛刻，需要用户搜索、加购物车、购买等；但是短视频场景，完播和点赞就能代表兴趣。因此，**短视频场景，用户多兴趣问题更严重**。

- 长期兴趣、多兴趣、长尾兴趣的关系

  - 长期兴趣 揭示 多兴趣
  - 多兴趣 的价值在于 长尾兴趣
  - 长期兴趣 辨别 长尾兴趣

- 整体架构

  - 训练阶段

    ![img](https://pic3.zhimg.com/v2-c86c04a5b7167e372e8ae579bf6ade16_1440w.jpg)

    - **训练公平的embedding**：item embedding和包含长期行为的SIM embedding协同学习
    - **建立item-类目的映射关系**：**VQ-VAE**，SIM embedding和item embedding的两级聚类（找最近邻）进行协同学习，建立item到类别ID的映射。

  - Serving阶段

    ![image-20250920225722171](C:\Users\Jarvis\AppData\Roaming\Typora\typora-user-images\image-20250920225722171.png)

    - 多兴趣（Trinity-M）：利用直方图统计出用户的类目消费次数，对那些次数多但欠分发的类目进行加强；*其中一级类目用于打散，二级类目用于决定哪些item被分发*
    - 长尾兴趣（Trinity-LT）：通过热度消偏来计算cluster是否为长尾兴趣，随后看用户的直方图在这些长尾主题上是不是有显著的兴趣表达，
    - 长期兴趣：用Trinity训练出的item embedding做基于ANN的i2i召回

  - **为什么不直接用item的1/2级真实类目？**

    - 真实类目会有类别item不平衡问题，热门类目下会有大量item；的而Trinity通过双塔+热度消偏，能实习类目平衡。

## 生成式推荐

### **Semantic ID**

（将item embedding量化为一组离散索引）

- 为什么有？
  - 业务视角：缓解冷启动和长尾问题
  - 技术视角：item embeeding表示空间太大，导致LLM的解空间太大；其次，其他的方式诸如item ID这种，不包含语义信息，无法准确建模item的关联。
- 计算方式
  - VQ量化：多层量化时，每一层都对**原始向量**在码本中寻找最近的语义表征
  - RQ量化：每次计算上一层索引之后的**残差，在下一层码本中寻找最近的语义表征
  - 码本坍塌：码本中大量码字没有被使用
    - 原因：只有被选中的码字才会更新梯度，其他的码字不更新
    - 解决方法
      - 降低学习率，稳定训练过程
      - 对于选中的码本，通过指数移动平均来更新，而不通过梯度下降；对于未被选中的码本，数据集中随机采样，重新初始化。
- 如何使用？
  - SID作为输入，通过embedding layer映射为embedding
  - 生成式推荐一般直接生成item的SID

### Decoder-Only架构

- 构建prefix：首先将用户的交互按照时间升序转成语义ID序列
- 然后需要对序列进行截断，可以采用比如训练一个summarizer，对长期历史做总结生成memory token，然后和短期历史做拼接
- 然后就是采用自回归生成候选，这一过程中我们需要预先建立KV-cache
  - KV-cache
    - 对prefix做一次前向，将每一步的KV存储起来
    - 之后生成新token时，只需要增量计算
  - 采用Beam Search一次生成多条序列

### Encoder-Decoder架构

- 构建prefix：按时间升序的交互事件，离散化为 token。
- 对序列进行分段：将历史拆成
  - 静态长程段 $$X^{(s)}$$：天/周级、不随请求快速变化；
  - 动态近程段 $$X^{(d)}$$：分钟/小时级，随请求更新。目的是支持离线缓存与在线增量。
- 编码器阶段（只做一次性计算）
  - 对 $$X=[X^{(s)},X^{(d)}]$$ 经过 Transformer Encoder（双向自注意力，非因果掩码）得到隐藏表示$$H=\mathrm{Enc}(X)\in\mathbb{R}^{L_{\text{enc}}\times d}.$$
  - 在这一过程中，实际上可以对长程段进行预计算并缓存；
  - 请求到来时仅对近程段 $$X^{(d)}$$ 前向，和 $$H^{(s)}$$ 拼接得到 $$H=[H^{(s)};H^{(d)}]$$。
  - 之后解码过程中，编码器不再计算；$$H$$ 作为交叉注意力的 K/V 被反复读取。
- 解码器阶段（依然采用自回归生成）
  - 以起始符和必要的控制 token初始化解码序列 $$Y$$（例如 <BOS>, <SURFACE=FEED>, <GOAL=CLICK> …）。
  - 第 t 步解码器计算：
    - 自注意力（因果）：对已生成前缀 $$Y_{<t}$$ 做增量前向，使用 KV-cache（仅为解码器自注意力维护）。
    - 交叉注意力：以当前查询 $$Q_t$$ 与固定的 $$H$$ 做一次$$\mathrm{Attn}(Q_t,\,K\!=\!H,\,V\!=\!H)$$ 读取用户历史信息。
- 工程优化要点
  - 双缓存机制：
    - Encoder-memory： $$H$$ 仅在首帧构建；所有 beam 共享同一 $$H$$。
    - Decoder KV-cache：自回归步进增量更新；与 decoder-only 相同做分块/量化（8/4-bit）、paged-KV、批内前缀合并（prefix batching）。

### OneRec

![img](https://pic1.zhimg.com/v2-17c7adcea94f6ca93693f1931a52e014_1440w.jpg)

- 核心创新点：采用end-to-end的生成式模型替换传统的级联式推荐架构
- 架构改进
  - 量化语义ID替换传统embedding：传统embedding对LLM无意义
  - Encoder-Decoder + MoE：遵循Scaling Law
  - session-wise generation：考虑session内item-item之间的关系
  - DPO进一步优化推荐结果：
    - 偏好pair：从beam search的结果中选
    - 如何选？ 预训练一个奖励模型，给beam search的结果打分，选分数最高的最低的组成偏好pair
- 问题
  - 为什么DPO不适用推荐系统？
    - 核心原因：DPO依赖用户标注的正负样本pair。在对话系统中，系统可以同时给用户展现一个请求的不同结果（比如给两个翻译结果，让用户标注好/坏）；但是推荐系统中，**不可能同时给用户推两个视频，让用户标注好/坏**。因此推荐系统中不存在DPO所需的，构建正负样本pair的条件。
    - 解决方法：训练一个奖励模型，来模拟用户对不同结果的评价。

# 大语言模型

## 对齐人类偏好

LLM的训练过程是无监督的，因此对其实现行为控制是非常困难的。因此我们需要**收集模型生成的人类标注，微调无监督的LLM**以符合这些偏好。

![img](https://picx.zhimg.com/v2-40882a7b4577f6f6102da852c84056e1_1440w.jpg)

### RLHF

- 特点： 训练奖励模型 + 用强化学习优化LLM
- 阶段一 （监督微调SFT）
  - 利用下游任务的数据对LLM进行SFT
- 阶段二（奖励模型）
  - 构建偏好数据集：LLM被输入一组Prompt，并生成一对回答，人类再标注哪个回答更好。
  - 建模偏好概率，得到参数化奖励函数
  - 最大似然估计优化
- 阶段三（强化学习）
  - 奖励函数为LLM提供反馈

### DPO

- 特点：直接提供监督信号优化LLM
